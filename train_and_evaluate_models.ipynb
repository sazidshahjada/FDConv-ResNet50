{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6874b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pynvml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from FDResnet50 import FDResNet, resnet50_fdconv\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from train_utils import train, evaluate\n",
    "from utils import print_generalized_model_summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde16e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = \"cuda\" if is_cuda else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "if is_cuda:\n",
    "    print(\"GPU Model:\", torch.cuda.get_device_name(0))\n",
    "    \n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "    info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"Total VRAM:     {info.total / 1024**3:.2f} GB\")\n",
    "    print(f\"Used VRAM:      {info.used / 1024**3:.2f} GB\")\n",
    "    print(f\"Free VRAM:      {info.free / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b14b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/media/iot/HDD2TB/eyepac-light-v2-512-jpg/train\"\n",
    "val_dir = \"/media/iot/HDD2TB/eyepac-light-v2-512-jpg/validation\"\n",
    "test_dir = \"/media/iot/HDD2TB/eyepac-light-v2-512-jpg/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.3569, 0.2274, 0.1467], std=[0.2309, 0.1543, 0.1033])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_class_samples(dataset, class_names, num_samples=5):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    class_to_idx = dataset.class_to_idx\n",
    "    \n",
    "    for c_idx, class_name in enumerate(class_names):\n",
    "        target_idx = class_to_idx[class_name]\n",
    "        indices = [i for i, (_, label) in enumerate(dataset.samples) if label == target_idx]\n",
    "        chosen_indices = indices[:num_samples]\n",
    "        \n",
    "        for j, idx in enumerate(chosen_indices):\n",
    "            img, label = dataset[idx]\n",
    "            img = img.permute(1, 2, 0) * 0.5 + 0.5\n",
    "            \n",
    "            plt.subplot(len(class_names), num_samples, c_idx * num_samples + j + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"{class_name}\")\n",
    "            plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_class_samples(train_dataset, class_names, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcccf875",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_counts = np.bincount([label for _, label in train_dataset.samples], minlength=num_classes)\n",
    "val_counts = np.bincount([label for _, label in val_dataset.samples], minlength=num_classes)\n",
    "test_counts = np.bincount([label for _, label in test_dataset.samples], minlength=num_classes)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}, class distribution: {dict(zip(class_names, train_counts))}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}, class distribution: {dict(zip(class_names, val_counts))}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}, class distribution: {dict(zip(class_names, test_counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = resnet50(weights=True)\n",
    "\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "in_features = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    \n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.3),\n",
    "    \n",
    "    nn.Linear(256, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    nn.Linear(128, num_classes)\n",
    ")\n",
    "\n",
    "print(f\"ResNet50 model created from scratch with {num_classes} output classes\")\n",
    "print(\"\\nResnet50 Model Summary:\")\n",
    "print_generalized_model_summary(resnet_model, model_name=\"Resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./model_checkpoints/resnet50\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "log_dir = './runs/resnet50'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Train ResNet50 with simplified training function\n",
    "print(\"Starting ResNet50 Training...\")\n",
    "trained_resnet, training_results = train(\n",
    "    model=resnet_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    optimizer_type='adam',\n",
    "    scheduler_type='plateau',\n",
    "    early_stopping_patience=5,\n",
    "    device=device,\n",
    "    save_dir=save_dir,\n",
    "    model_name='resnet50_trained',\n",
    "    tensorboard_log_dir=log_dir,\n",
    "    print_freq=100,\n",
    "    save_best_only=True,\n",
    "    mixed_precision=True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    weight_decay=1e-4,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "# Get training results\n",
    "best_val_acc = training_results['best_val_acc']\n",
    "total_epochs = len(training_results['train_losses'])\n",
    "\n",
    "print(f\"\\nTraining Complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"Total epochs: {total_epochs}\")\n",
    "print(f\"Final train accuracy: {training_results['train_accs'][-1]:.2f}%\")\n",
    "print(f\"Final val accuracy: {training_results['val_accs'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ResNet50 on Test Set\n",
    "print(\"Evaluating ResNet50 on Test Set...\")\n",
    "\n",
    "# Load the best model\n",
    "best_model_path = os.path.join(save_dir, 'resnet50_enhanced_best.pth')\n",
    "if os.path.exists(best_model_path):\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    trained_resnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = evaluate(\n",
    "    model=trained_resnet,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    save_dir=\"./evaluation_results\",\n",
    "    model_name=\"resnet50_enhanced\"\n",
    ")\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"\\nResNet50 Test Results:\")\n",
    "print(f\"  Test Accuracy: {eval_results['accuracy']:.2f}%\")\n",
    "print(f\"  Test Loss: {eval_results['test_loss']:.6f}\")\n",
    "print(f\"  Evaluation Time: {eval_results['evaluation_time']:.2f} seconds\")\n",
    "print(f\"  Total samples evaluated: {eval_results['num_samples']}\")\n",
    "\n",
    "# Print per-class accuracy\n",
    "if 'class_accuracies' in eval_results:\n",
    "    print(f\"\\nPer-class Accuracies:\")\n",
    "    for i, (class_name, acc) in enumerate(zip(class_names, eval_results['class_accuracies'])):\n",
    "        print(f\"  {class_name}: {acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nResults saved to: ./evaluation_results/\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
